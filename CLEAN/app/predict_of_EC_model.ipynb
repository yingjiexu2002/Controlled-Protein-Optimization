{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用CLEAN模型对模型输出的结果进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEAN github：https://github.com/tttianhao/CLEAN?tab=readme-ov-file \\\n",
    "Paper：https://www.science.org/doi/10.1126/science.adf2465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 处理输入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sequence     score\n",
      "0  MSDNQAPKLTFVSLGCPKALVDSERILTQLRSEGYDLVAKYDDADV...  0.303411\n",
      "1  MITIGITGGIGSGKTTVARYFREHGVPVVDADIIAREVVRPGSECL...  1.017966\n",
      "2  MNTPQIIKNESEAIKIAILSGSFNLTNYGAMKDVFANNAEIIKSIG...  1.883462\n",
      "3  MANKYIVSWDMLQIHARKLASRLMPSEQWKGIIAVSRGGLVPGALL...  0.114259\n",
      "4  MKVFLDTANVDEIKKANALGVISGVTTNPSLIAKEGRNFEEVINEI...  0.475771\n",
      "(5120, 2)\n"
     ]
    }
   ],
   "source": [
    "# EC生成模型输出的文件为txt格式\n",
    "# 放在EC_training/output_samples/文件夹下\n",
    "\n",
    "label = '2'\n",
    "p = 0.75\n",
    "version = '6'\n",
    "input_file_path = '../../EC_training/output_samples/'+version+'_samples_EC_label_'+label+'_'+str(p)+'.txt'\n",
    "train_data = 'split100'\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv(input_file_path, header=None, names=['sequence', 'score'])\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除去不合格的序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sequence     score\n",
      "0  MSDNQAPKLTFVSLGCPKALVDSERILTQLRSEGYDLVAKYDDADV...  0.303411\n",
      "1  MITIGITGGIGSGKTTVARYFREHGVPVVDADIIAREVVRPGSECL...  1.017966\n",
      "2  MNTPQIIKNESEAIKIAILSGSFNLTNYGAMKDVFANNAEIIKSIG...  1.883462\n",
      "3  MANKYIVSWDMLQIHARKLASRLMPSEQWKGIIAVSRGGLVPGALL...  0.114259\n",
      "4  MKVFLDTANVDEIKKANALGVISGVTTNPSLIAKEGRNFEEVINEI...  0.475771\n",
      "(4264, 2)\n"
     ]
    }
   ],
   "source": [
    "# 去除df中长度大于等于508的序列\n",
    "df = df[df['sequence'].apply(lambda x: len(x) < 508)]\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# # 选择score排行前80%的数据作为评估集合\n",
    "# df = df.sort_values(by='score', ascending=True) # 从小到大排序\n",
    "# df = df.head(int((df.shape[0])*0.8))        # 选择前80%\n",
    "# print(df.head())\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将txt转化为fasta格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将df输出到inputs文件夹下，以fasta格式\n",
    "output_file_path = 'data/inputs/1_samples_EC_label_'+label+'_'+str(p)+'.fasta'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    for i in range(df.shape[0]):\n",
    "        f.write('>sample'+str(i)+'\\n')\n",
    "        f.write(df.iloc[i]['sequence']+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 将数据输入模型中，进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred model to GPU\n",
      "Read data/inputs/1_samples_EC_label_2_0.75.fasta with 4264 sequences\n",
      "Processing 1 of 271 batches (60 sequences)\n",
      "Processing 2 of 271 batches (49 sequences)\n",
      "Processing 3 of 271 batches (44 sequences)\n",
      "Processing 4 of 271 batches (44 sequences)\n",
      "Processing 5 of 271 batches (43 sequences)\n",
      "Processing 6 of 271 batches (39 sequences)\n",
      "Processing 7 of 271 batches (35 sequences)\n",
      "Processing 8 of 271 batches (34 sequences)\n",
      "Processing 9 of 271 batches (32 sequences)\n",
      "Processing 10 of 271 batches (32 sequences)\n",
      "Processing 11 of 271 batches (32 sequences)\n",
      "Processing 12 of 271 batches (31 sequences)\n",
      "Processing 13 of 271 batches (30 sequences)\n",
      "Processing 14 of 271 batches (29 sequences)\n",
      "Processing 15 of 271 batches (29 sequences)\n",
      "Processing 16 of 271 batches (29 sequences)\n",
      "Processing 17 of 271 batches (28 sequences)\n",
      "Processing 18 of 271 batches (28 sequences)\n",
      "Processing 19 of 271 batches (28 sequences)\n",
      "Processing 20 of 271 batches (28 sequences)\n",
      "Processing 21 of 271 batches (28 sequences)\n",
      "Processing 22 of 271 batches (28 sequences)\n",
      "Processing 23 of 271 batches (27 sequences)\n",
      "Processing 24 of 271 batches (26 sequences)\n",
      "Processing 25 of 271 batches (26 sequences)\n",
      "Processing 26 of 271 batches (26 sequences)\n",
      "Processing 27 of 271 batches (26 sequences)\n",
      "Processing 28 of 271 batches (25 sequences)\n",
      "Processing 29 of 271 batches (25 sequences)\n",
      "Processing 30 of 271 batches (25 sequences)\n",
      "Processing 31 of 271 batches (25 sequences)\n",
      "Processing 32 of 271 batches (25 sequences)\n",
      "Processing 33 of 271 batches (25 sequences)\n",
      "Processing 34 of 271 batches (24 sequences)\n",
      "Processing 35 of 271 batches (23 sequences)\n",
      "Processing 36 of 271 batches (23 sequences)\n",
      "Processing 37 of 271 batches (23 sequences)\n",
      "Processing 38 of 271 batches (23 sequences)\n",
      "Processing 39 of 271 batches (22 sequences)\n",
      "Processing 40 of 271 batches (22 sequences)\n",
      "Processing 41 of 271 batches (22 sequences)\n",
      "Processing 42 of 271 batches (21 sequences)\n",
      "Processing 43 of 271 batches (21 sequences)\n",
      "Processing 44 of 271 batches (21 sequences)\n",
      "Processing 45 of 271 batches (20 sequences)\n",
      "Processing 46 of 271 batches (20 sequences)\n",
      "Processing 47 of 271 batches (20 sequences)\n",
      "Processing 48 of 271 batches (20 sequences)\n",
      "Processing 49 of 271 batches (20 sequences)\n",
      "Processing 50 of 271 batches (20 sequences)\n",
      "Processing 51 of 271 batches (20 sequences)\n",
      "Processing 52 of 271 batches (19 sequences)\n",
      "Processing 53 of 271 batches (19 sequences)\n",
      "Processing 54 of 271 batches (19 sequences)\n",
      "Processing 55 of 271 batches (19 sequences)\n",
      "Processing 56 of 271 batches (19 sequences)\n",
      "Processing 57 of 271 batches (19 sequences)\n",
      "Processing 58 of 271 batches (19 sequences)\n",
      "Processing 59 of 271 batches (19 sequences)\n",
      "Processing 60 of 271 batches (19 sequences)\n",
      "Processing 61 of 271 batches (19 sequences)\n",
      "Processing 62 of 271 batches (19 sequences)\n",
      "Processing 63 of 271 batches (19 sequences)\n",
      "Processing 64 of 271 batches (19 sequences)\n",
      "Processing 65 of 271 batches (19 sequences)\n",
      "Processing 66 of 271 batches (19 sequences)\n",
      "Processing 67 of 271 batches (19 sequences)\n",
      "Processing 68 of 271 batches (19 sequences)\n",
      "Processing 69 of 271 batches (19 sequences)\n",
      "Processing 70 of 271 batches (19 sequences)\n",
      "Processing 71 of 271 batches (19 sequences)\n",
      "Processing 72 of 271 batches (19 sequences)\n",
      "Processing 73 of 271 batches (19 sequences)\n",
      "Processing 74 of 271 batches (19 sequences)\n",
      "Processing 75 of 271 batches (18 sequences)\n",
      "Processing 76 of 271 batches (18 sequences)\n",
      "Processing 77 of 271 batches (18 sequences)\n",
      "Processing 78 of 271 batches (18 sequences)\n",
      "Processing 79 of 271 batches (18 sequences)\n",
      "Processing 80 of 271 batches (18 sequences)\n",
      "Processing 81 of 271 batches (18 sequences)\n",
      "Processing 82 of 271 batches (18 sequences)\n",
      "Processing 83 of 271 batches (18 sequences)\n",
      "Processing 84 of 271 batches (18 sequences)\n",
      "Processing 85 of 271 batches (17 sequences)\n",
      "Processing 86 of 271 batches (17 sequences)\n",
      "Processing 87 of 271 batches (17 sequences)\n",
      "Processing 88 of 271 batches (17 sequences)\n",
      "Processing 89 of 271 batches (17 sequences)\n",
      "Processing 90 of 271 batches (17 sequences)\n",
      "Processing 91 of 271 batches (17 sequences)\n",
      "Processing 92 of 271 batches (17 sequences)\n",
      "Processing 93 of 271 batches (17 sequences)\n",
      "Processing 94 of 271 batches (16 sequences)\n",
      "Processing 95 of 271 batches (16 sequences)\n",
      "Processing 96 of 271 batches (16 sequences)\n",
      "Processing 97 of 271 batches (16 sequences)\n",
      "Processing 98 of 271 batches (16 sequences)\n",
      "Processing 99 of 271 batches (16 sequences)\n",
      "Processing 100 of 271 batches (16 sequences)\n",
      "Processing 101 of 271 batches (16 sequences)\n",
      "Processing 102 of 271 batches (16 sequences)\n",
      "Processing 103 of 271 batches (16 sequences)\n",
      "Processing 104 of 271 batches (16 sequences)\n",
      "Processing 105 of 271 batches (16 sequences)\n",
      "Processing 106 of 271 batches (16 sequences)\n",
      "Processing 107 of 271 batches (16 sequences)\n",
      "Processing 108 of 271 batches (15 sequences)\n",
      "Processing 109 of 271 batches (15 sequences)\n",
      "Processing 110 of 271 batches (15 sequences)\n",
      "Processing 111 of 271 batches (15 sequences)\n",
      "Processing 112 of 271 batches (15 sequences)\n",
      "Processing 113 of 271 batches (15 sequences)\n",
      "Processing 114 of 271 batches (15 sequences)\n",
      "Processing 115 of 271 batches (15 sequences)\n",
      "Processing 116 of 271 batches (15 sequences)\n",
      "Processing 117 of 271 batches (15 sequences)\n",
      "Processing 118 of 271 batches (15 sequences)\n",
      "Processing 119 of 271 batches (15 sequences)\n",
      "Processing 120 of 271 batches (14 sequences)\n",
      "Processing 121 of 271 batches (14 sequences)\n",
      "Processing 122 of 271 batches (14 sequences)\n",
      "Processing 123 of 271 batches (14 sequences)\n",
      "Processing 124 of 271 batches (14 sequences)\n",
      "Processing 125 of 271 batches (14 sequences)\n",
      "Processing 126 of 271 batches (14 sequences)\n",
      "Processing 127 of 271 batches (14 sequences)\n",
      "Processing 128 of 271 batches (14 sequences)\n",
      "Processing 129 of 271 batches (14 sequences)\n",
      "Processing 130 of 271 batches (14 sequences)\n",
      "Processing 131 of 271 batches (13 sequences)\n",
      "Processing 132 of 271 batches (13 sequences)\n",
      "Processing 133 of 271 batches (13 sequences)\n",
      "Processing 134 of 271 batches (13 sequences)\n",
      "Processing 135 of 271 batches (13 sequences)\n",
      "Processing 136 of 271 batches (13 sequences)\n",
      "Processing 137 of 271 batches (13 sequences)\n",
      "Processing 138 of 271 batches (13 sequences)\n",
      "Processing 139 of 271 batches (13 sequences)\n",
      "Processing 140 of 271 batches (13 sequences)\n",
      "Processing 141 of 271 batches (13 sequences)\n",
      "Processing 142 of 271 batches (13 sequences)\n",
      "Processing 143 of 271 batches (13 sequences)\n",
      "Processing 144 of 271 batches (13 sequences)\n",
      "Processing 145 of 271 batches (13 sequences)\n",
      "Processing 146 of 271 batches (13 sequences)\n",
      "Processing 147 of 271 batches (13 sequences)\n",
      "Processing 148 of 271 batches (13 sequences)\n",
      "Processing 149 of 271 batches (13 sequences)\n",
      "Processing 150 of 271 batches (13 sequences)\n",
      "Processing 151 of 271 batches (13 sequences)\n",
      "Processing 152 of 271 batches (13 sequences)\n",
      "Processing 153 of 271 batches (13 sequences)\n",
      "Processing 154 of 271 batches (13 sequences)\n",
      "Processing 155 of 271 batches (13 sequences)\n",
      "Processing 156 of 271 batches (12 sequences)\n",
      "Processing 157 of 271 batches (12 sequences)\n",
      "Processing 158 of 271 batches (12 sequences)\n",
      "Processing 159 of 271 batches (12 sequences)\n",
      "Processing 160 of 271 batches (12 sequences)\n",
      "Processing 161 of 271 batches (12 sequences)\n",
      "Processing 162 of 271 batches (12 sequences)\n",
      "Processing 163 of 271 batches (12 sequences)\n",
      "Processing 164 of 271 batches (12 sequences)\n",
      "Processing 165 of 271 batches (12 sequences)\n",
      "Processing 166 of 271 batches (12 sequences)\n",
      "Processing 167 of 271 batches (12 sequences)\n",
      "Processing 168 of 271 batches (12 sequences)\n",
      "Processing 169 of 271 batches (12 sequences)\n",
      "Processing 170 of 271 batches (12 sequences)\n",
      "Processing 171 of 271 batches (12 sequences)\n",
      "Processing 172 of 271 batches (12 sequences)\n",
      "Processing 173 of 271 batches (12 sequences)\n",
      "Processing 174 of 271 batches (12 sequences)\n",
      "Processing 175 of 271 batches (12 sequences)\n",
      "Processing 176 of 271 batches (12 sequences)\n",
      "Processing 177 of 271 batches (12 sequences)\n",
      "Processing 178 of 271 batches (12 sequences)\n",
      "Processing 179 of 271 batches (12 sequences)\n",
      "Processing 180 of 271 batches (12 sequences)\n",
      "Processing 181 of 271 batches (12 sequences)\n",
      "Processing 182 of 271 batches (11 sequences)\n",
      "Processing 183 of 271 batches (11 sequences)\n",
      "Processing 184 of 271 batches (11 sequences)\n",
      "Processing 185 of 271 batches (11 sequences)\n",
      "Processing 186 of 271 batches (11 sequences)\n",
      "Processing 187 of 271 batches (11 sequences)\n",
      "Processing 188 of 271 batches (11 sequences)\n",
      "Processing 189 of 271 batches (11 sequences)\n",
      "Processing 190 of 271 batches (11 sequences)\n",
      "Processing 191 of 271 batches (11 sequences)\n",
      "Processing 192 of 271 batches (11 sequences)\n",
      "Processing 193 of 271 batches (11 sequences)\n",
      "Processing 194 of 271 batches (11 sequences)\n",
      "Processing 195 of 271 batches (11 sequences)\n",
      "Processing 196 of 271 batches (11 sequences)\n",
      "Processing 197 of 271 batches (11 sequences)\n",
      "Processing 198 of 271 batches (11 sequences)\n",
      "Processing 199 of 271 batches (11 sequences)\n",
      "Processing 200 of 271 batches (11 sequences)\n",
      "Processing 201 of 271 batches (11 sequences)\n",
      "Processing 202 of 271 batches (11 sequences)\n",
      "Processing 203 of 271 batches (11 sequences)\n",
      "Processing 204 of 271 batches (11 sequences)\n",
      "Processing 205 of 271 batches (11 sequences)\n",
      "Processing 206 of 271 batches (11 sequences)\n",
      "Processing 207 of 271 batches (11 sequences)\n",
      "Processing 208 of 271 batches (11 sequences)\n",
      "Processing 209 of 271 batches (11 sequences)\n",
      "Processing 210 of 271 batches (11 sequences)\n",
      "Processing 211 of 271 batches (11 sequences)\n",
      "Processing 212 of 271 batches (11 sequences)\n",
      "Processing 213 of 271 batches (11 sequences)\n",
      "Processing 214 of 271 batches (10 sequences)\n",
      "Processing 215 of 271 batches (10 sequences)\n",
      "Processing 216 of 271 batches (10 sequences)\n",
      "Processing 217 of 271 batches (10 sequences)\n",
      "Processing 218 of 271 batches (10 sequences)\n",
      "Processing 219 of 271 batches (10 sequences)\n",
      "Processing 220 of 271 batches (10 sequences)\n",
      "Processing 221 of 271 batches (10 sequences)\n",
      "Processing 222 of 271 batches (10 sequences)\n",
      "Processing 223 of 271 batches (10 sequences)\n",
      "Processing 224 of 271 batches (10 sequences)\n",
      "Processing 225 of 271 batches (10 sequences)\n",
      "Processing 226 of 271 batches (10 sequences)\n",
      "Processing 227 of 271 batches (10 sequences)\n",
      "Processing 228 of 271 batches (10 sequences)\n",
      "Processing 229 of 271 batches (10 sequences)\n",
      "Processing 230 of 271 batches (10 sequences)\n",
      "Processing 231 of 271 batches (10 sequences)\n",
      "Processing 232 of 271 batches (10 sequences)\n",
      "Processing 233 of 271 batches (10 sequences)\n",
      "Processing 234 of 271 batches (10 sequences)\n",
      "Processing 235 of 271 batches (10 sequences)\n",
      "Processing 236 of 271 batches (9 sequences)\n",
      "Processing 237 of 271 batches (9 sequences)\n",
      "Processing 238 of 271 batches (9 sequences)\n",
      "Processing 239 of 271 batches (9 sequences)\n",
      "Processing 240 of 271 batches (9 sequences)\n",
      "Processing 241 of 271 batches (9 sequences)\n",
      "Processing 242 of 271 batches (9 sequences)\n",
      "Processing 243 of 271 batches (9 sequences)\n",
      "Processing 244 of 271 batches (9 sequences)\n",
      "Processing 245 of 271 batches (9 sequences)\n",
      "Processing 246 of 271 batches (9 sequences)\n",
      "Processing 247 of 271 batches (9 sequences)\n",
      "Processing 248 of 271 batches (9 sequences)\n",
      "Processing 249 of 271 batches (9 sequences)\n",
      "Processing 250 of 271 batches (9 sequences)\n",
      "Processing 251 of 271 batches (9 sequences)\n",
      "Processing 252 of 271 batches (9 sequences)\n",
      "Processing 253 of 271 batches (9 sequences)\n",
      "Processing 254 of 271 batches (9 sequences)\n",
      "Processing 255 of 271 batches (8 sequences)\n",
      "Processing 256 of 271 batches (8 sequences)\n",
      "Processing 257 of 271 batches (8 sequences)\n",
      "Processing 258 of 271 batches (8 sequences)\n",
      "Processing 259 of 271 batches (8 sequences)\n",
      "Processing 260 of 271 batches (8 sequences)\n",
      "Processing 261 of 271 batches (8 sequences)\n",
      "Processing 262 of 271 batches (8 sequences)\n",
      "Processing 263 of 271 batches (8 sequences)\n",
      "Processing 264 of 271 batches (8 sequences)\n",
      "Processing 265 of 271 batches (8 sequences)\n",
      "Processing 266 of 271 batches (8 sequences)\n",
      "Processing 267 of 271 batches (8 sequences)\n",
      "Processing 268 of 271 batches (8 sequences)\n",
      "Processing 269 of 271 batches (8 sequences)\n",
      "Processing 270 of 271 batches (8 sequences)\n",
      "Processing 271 of 271 batches (2 sequences)\n",
      "Command ran successfully\n"
     ]
    }
   ],
   "source": [
    "# 将需要预测的fasta文件放在outputs文件夹下\n",
    "# 输出的ESM嵌入文件放在outputs/esm_data文件夹下\n",
    "import csv\n",
    "import subprocess\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "def retrive_esm1b_embedding(fasta_name):\n",
    "    esm_script = \"esm/scripts/extract.py\"   # 用于提取ESM（Evolutionary Scale Modeling）嵌入的Python脚本的路径\n",
    "    esm_out = \"data/esm_data\"   # ESM嵌入的输出目录\n",
    "    esm_type = \"esm1b_t33_650M_UR50S\"   # ESM模型的类型\n",
    "    fasta_name = \"data/\" + fasta_name + \".fasta\"\n",
    "    command = [\"python\", esm_script, esm_type, \n",
    "              fasta_name, esm_out, \"--include\", \"mean\"]\n",
    "    result = subprocess.run(command)\n",
    "    return result.returncode\n",
    "\n",
    "\n",
    "def prepare_infer_fasta(fasta_name):\n",
    "    # e.g. fasta_name = 'inputs/1_samples_EC_label_3.6.4.12_0.5'\n",
    "    # retrive_esm1b_embedding(fasta_name) \n",
    "    returncode = retrive_esm1b_embedding(fasta_name)    # 提取ESM嵌入\n",
    "    if returncode == 0:\n",
    "        print(\"Command ran successfully\")\n",
    "    else:\n",
    "        print(\"Command failed with return code:\", returncode)\n",
    "    csvfile = open('data/' + fasta_name +'.csv', 'w', newline='')\n",
    "    csvwriter = csv.writer(csvfile, delimiter = '\\t')\n",
    "    csvwriter.writerow(['Entry', 'EC number', 'Sequence'])  # 写入列名\n",
    "    fastafile = open('data/' + fasta_name +'.fasta', 'r')\n",
    "    for i in fastafile.readlines():\n",
    "        if i[0] == '>':\n",
    "            csvwriter.writerow([i.strip()[1:], ' ', ' '])\n",
    "\n",
    "fasta_data = '1_samples_EC_label_'+label+'_'+str(p)\n",
    "test_data = 'inputs/' + fasta_data\n",
    "prepare_infer_fasta(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding sizes for train and test: torch.Size([241025, 128]) torch.Size([4264, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5242/5242 [00:00<00:00, 39568.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating eval distance map, between 4264 test ids and 5242 train EC cluster centers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4264it [00:04, 1037.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.CLEAN.model import LayerNormNet\n",
    "from src.CLEAN.utils import * \n",
    "from src.CLEAN.evaluate import *\n",
    "\n",
    "def infer_maxsep(train_data, test_data, report_metrics = False, \n",
    "                 pretrained=True, model_name=None, gmm = None):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    dtype = torch.float32\n",
    "    id_ec_train, ec_id_dict_train = get_ec_id_dict('data/' + train_data + '.csv')\n",
    "    id_ec_test, _ = get_ec_id_dict('data/' + test_data + '.csv')\n",
    "    # load checkpoints\n",
    "    # NOTE: change this to LayerNormNet(512, 256, device, dtype) \n",
    "    # and rebuild with [python build.py install]\n",
    "    # if inferencing on model trained with supconH loss\n",
    "    model = LayerNormNet(512, 128, device, dtype)\n",
    "    \n",
    "    if pretrained:\n",
    "        try:\n",
    "            checkpoint = torch.load('data/pretrained/'+ train_data +'.pth', map_location=device)\n",
    "        except FileNotFoundError as error:\n",
    "            raise Exception('No pretrained weights for this training data')\n",
    "    else:\n",
    "        try:\n",
    "            checkpoint = torch.load('data/model/'+ model_name +'.pth', map_location=device)\n",
    "        except FileNotFoundError as error:\n",
    "            raise Exception('No model found!')\n",
    "            \n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    # load precomputed EC cluster center embeddings if possible\n",
    "    if train_data == \"split70\":\n",
    "        emb_train = torch.load('data/pretrained/70.pt', map_location=device)\n",
    "    elif train_data == \"split100\":\n",
    "        emb_train = torch.load('data/pretrained/100.pt', map_location=device)\n",
    "    else:\n",
    "        emb_train = model(esm_embedding(ec_id_dict_train, device, dtype))\n",
    "        \n",
    "    emb_test = model_embedding_test(id_ec_test, model, device, dtype)\n",
    "    eval_dist = get_dist_map_test(emb_train, emb_test, ec_id_dict_train, id_ec_test, device, dtype)\n",
    "    seed_everything()\n",
    "    eval_df = pd.DataFrame.from_dict(eval_dist)\n",
    "    ensure_dirs(\"results\")\n",
    "    out_filename = \"results/\" +  test_data\n",
    "    write_max_sep_choices(eval_df, out_filename, gmm=gmm)\n",
    "    if report_metrics:\n",
    "        pred_label = get_pred_labels(out_filename, pred_type='_maxsep')\n",
    "        pred_probs = get_pred_probs(out_filename, pred_type='_maxsep')\n",
    "        true_label, all_label = get_true_labels('data/' + test_data)\n",
    "        pre, rec, f1, roc, acc = get_eval_metrics(\n",
    "            pred_label, pred_probs, true_label, all_label)\n",
    "        print(\"############ EC calling results using maximum separation ############\")\n",
    "        print('-' * 75)\n",
    "        print(f'>>> total samples: {len(true_label)} | total ec: {len(all_label)} \\n'\n",
    "            f'>>> precision: {pre:.3} | recall: {rec:.3}'\n",
    "            f'| F1: {f1:.3} | AUC: {roc:.3} ')\n",
    "        print('-' * 75)\n",
    "\n",
    "\n",
    "infer_maxsep(train_data, test_data, report_metrics=False, pretrained=True, gmm = 'data/pretrained/gmm_ensumble.pkl')\n",
    "# removing dummy csv file\n",
    "os.remove(\"data/\"+ test_data +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 对生成的结果文件进行分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sequence           EC_number\n",
      "0  sample0   EC:2.8.4.4/0.9980\n",
      "1  sample1  EC:2.7.1.24/0.9974\n",
      "2  sample2  EC:6.2.1.14/0.0000\n",
      "3  sample3  EC:2.4.2.22/0.9953\n",
      "4  sample4   EC:2.2.1.2/0.9886\n",
      "  sequence EC_number\n",
      "0  sample0         2\n",
      "1  sample1         2\n",
      "2  sample2         6\n",
      "3  sample3         2\n",
      "4  sample4         2\n"
     ]
    }
   ],
   "source": [
    "# 读取上面的csv文件，得到预测结果\n",
    "df = pd.read_csv('results/'+test_data+'_maxsep.csv', header=None, names=['sequence', 'EC_number'], usecols=[0, 1])    # 只读取第0列和第1列，防止异常数据\n",
    "print(df.head())\n",
    "\n",
    "# 处理EC_number列，得到纯EC编号的string格式\n",
    "label_split = label.split('.')\n",
    "if len(label_split) == 4:\n",
    "    df['EC_number'] = df['EC_number'].apply(lambda x: x.split('.')[0][3:]+'.'+x.split('.')[1]+'.'+x.split('.')[2]+'.'+x.split('.')[3][:-2])\n",
    "elif len(label_split) == 3:\n",
    "    df['EC_number'] = df['EC_number'].apply(lambda x: x.split('.')[0][3:]+'.'+x.split('.')[1]+'.'+x.split('.')[2])\n",
    "elif len(label_split) == 2:\n",
    "    df['EC_number'] = df['EC_number'].apply(lambda x: x.split('.')[0][3:]+'.'+x.split('.')[1])\n",
    "else:\n",
    "    df['EC_number'] = df['EC_number'].apply(lambda x: x.split('.')[0][3:])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC_number\n",
      "2    3634\n",
      "6     215\n",
      "1     146\n",
      "3     140\n",
      "4      84\n",
      "5      37\n",
      "7       8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 输出预测结果中每个EC编号的数量\n",
    "print(df['EC_number'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.输出最终准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8522514071294559\n"
     ]
    }
   ],
   "source": [
    "# 输出最终的生成准确率\n",
    "print(df[df['EC_number'] == label].shape[0]/df.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
